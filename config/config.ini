[data]
# static data and csv data root path
data_path = data/
# data source: csv or database
data_source=csv

[data.static]
# relative to data.data_path
river_stations_mapping_path = raw/station-mapping.json
river_stations_metadata_path = raw/station-metadata.csv

[data.csv]
# relative to data.data_path
weather_history_data_path = raw/weather-history.csv
weather_forecast_data_path = raw/weather-forecast.csv
river_stations_data_path = raw/station-data.csv

[data.database]
dbname = postgres
user = postgres
host = 68.183.13.232
port = 5432

[openmeteo]
api_url = https://api.open-meteo.com/v1/forecast
api_archive_url = https://archive-api.open-meteo.com/v1/archive
store_base_path = src/flood_forecaster/data_ingestion/data/

[swalim]
river_level_api_url = https://frrims.faoswalim.org/rivers/levels

[data]
data_path = data
station_metadata_file = %(data_path)s/river_stations_metadata.csv
#TODO More useful name
district_data_file = %(data_path)s/district-data.csv
station_data_file = %(data_path)s/station-data.csv

[model]
exclude_today_river_level = true

# The number of days to lag the weather data by (0 and negative values are forecasts)
weather_lag_days = [1, 3, 7, 14, 30, 0, -2, -6]

# The number of days to lag the river levels data by
river_station_lag_days = [1, 3, 7, 14, 30]

# The number of days to forecast into the future
forecast_days = 1

# The date to split the data on for training and testing
train_test_date_split = 2023-10-01

# preprocessed data path
preprocessed_data_path = data/interim/injestion/

# analysis data path
analysis_data_path = data/interim/analysis/

# preprocessor to use
preprocessor_type = Preprocessor_001

# training data path
training_data_path = data/interim/training/

# evaluation data path
evaluation_data_path = data/interim/evaluation/

# The model to train/evaluate/inference
#  - RandomForestRegressor_001
model_type = XGBoost_001

# Where to save the models
model_path = models/
